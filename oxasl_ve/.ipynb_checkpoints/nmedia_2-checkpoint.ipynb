{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image SNR in Python Tutorial\n",
    "\n",
    "This notebook goes through a method for calculating a measure of signal to noise ratio (SNR) for an image in Python. There is no single standardised method for measuring SNR in an MRI image, but many methods are based on the fundamental definition:\n",
    "\n",
    "$\\textrm{iSNR} = \\frac{Mean\\left(\\textrm{Foreground Voxels}\\right)}{\\sigma\\left\n",
    "(\\textrm{Background Voxels}\\right)} \\times \\sqrt{2 - \\frac{\\pi}{2}}$\n",
    "\n",
    "To use this, we need to identify parts of the image which are foreground and parts which are background.\n",
    "\n",
    "We'll be using functions from the numpy and sklearn (machine learning) packages as well as the matplotlib package for displaying images, so we will start by importing these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll load some example T2W structural data from the UK renal imaging network's kidney analysis toolkit (ukat): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data\n",
    "from ukat.data import fetch\n",
    "data, affine = fetch.t2w_volume_philips()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: ```data``` is a Numpy array - can you display the image voxel dimensions?**\n",
    "\n",
    "**Task: Using Matplotlib, plot a slice through the data as a greyscale image using slice number 7 in the Z direction**\n",
    "\n",
    "**Task: Print ```affine``` - what do you think this data describes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use a clustering method to identify the background and foreground voxels. The method we will use is a Gaussian mixture model which models the signal intensity of each part of the image as a Gaussian and performs a Bayesian inference process to identify the most probable set of intensity clusters. So if we ask for 3 clusters it will try to model the intensity histogram as closely as possible using 3 Gaussians. This algorithm is part of the sklearn library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4.40525497e+00]]\n",
      "\n",
      " [[9.12059909e+04]]\n",
      "\n",
      " [[1.28184919e+04]]]\n",
      "[[  1.10461385]\n",
      " [564.08079105]\n",
      " [186.25537437]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "gmm = sklearn.mixture.BayesianGaussianMixture(n_components=3, random_state=0, max_iter=500)\n",
    "data_2d = data.reshape(-1, 1)\n",
    "gmm.fit(data_2d)\n",
    "print(gmm.means_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values displayed above means that sklearn has divided the image into 3 regions, and these are the mean intensities in each region. You should see that one is much lower than the other - this is most likely to represent the background.\n",
    "\n",
    "**Task: Above we defined ```data_2d = data.reshape(-1, 1)``` - can you explain what this code does?** \n",
    "\n",
    "We can also predict which of these clusters each voxel in the image belongs to as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 13)\n",
      "(256, 256, 13)\n"
     ]
    }
   ],
   "source": [
    "clusters = gmm.predict(data_2d).reshape(data.shape)\n",
    "print(clusters.shape)\n",
    "cluster_1 = (clusters == 1)\n",
    "print(cluster_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, ```clusters``` is an array like the original image but containing numbers 0, 1, 2 depending on which cluster each voxel was most likely to belong to. ```cluster_1``` is a binary image which contains ```True``` for voxels that were in the cluster with index 1.\n",
    "\n",
    "**Task: Define binary images for clusters 0 and 2, and plot all three as a slice in the Z direction, in the same way as you plotted the original data. Use the 'inferno' colour map in matplotlib to distinguish the regions more easily. Check that the cluster with the lowest mean value does indeed represent the background of the image**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SNR, we want to calculate the mean in foreground voxels and the standard deviation in background voxels. For example if we decided that cluster 2 was the background we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = (clusters == 2)\n",
    "foreground = ~background\n",
    "\n",
    "mean_foreground = np.mean(foreground)\n",
    "# std_background = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: Explain what the code ```foreground = ~background``` does**\n",
    "\n",
    "**Task: Add code above to calculate the standard deviation of the background cluster**\n",
    "\n",
    "**Task: Calculate and display SNR using the formula given at the start of the notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deciding how many clusters to use in this method is not obvious, but usually 3 works quite well.\n",
    "\n",
    "**Task: Try repeating the above with 2 or 4 clusters and see how much this changes the result**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, iSNR maps can be generated. These are calculated by dividing the image by the standard deviation of the noise\n",
    "and multiplying it by the Rician correction factor. This is useful for visualising the noise in the image.\n",
    "\n",
    "**Task: Calculate and plot the iSNR map for the same slice we used when displaying the original data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extension task:** Calculate iSNR for these additional data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T2W data\n",
    "data, affine = fetch.t2w_volume_philips()\n",
    "\n",
    "# T1W data\n",
    "data, affine = fetch.t1w_volume_philips()\n",
    "\n",
    "#T2* data\n",
    "data, affine, te = fetch.t2star_philips()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Super-expert task:** Can you plot a histogram of voxel intensity for the original image, and also histograms on the same scale showing the Gaussian clusters the GMM has found (hint: ``gmm.covariances_`` gives the variance of each of the Gaussians to go with the means that you already have)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Signal to Noise Ratio (tSNR)\n",
    "Here we will use two datasets as examples of high and low tSNR. Both are FAIR ASL sequences however the high tSNR data was\n",
    "acquired a body coil while the low tSNR data was acquired using the receive coil built into the bore of the magnet. Additional Gaussian noise was also added to the low tSNR data.\n",
    "\n",
    "Each dataset will be fetched, a tSNR map calculated and the output saved as a nifti. The resulting tSNR maps will also be displayed in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe4f19b713543e19a81db5ef756966b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ? MB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'OUTPUT_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2211/2461747470.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhigh_tsnr_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTsnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhigh_tsnr_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh_tsnr_affine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Save as nifti\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhigh_tsnr_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_nifti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'high_quality_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Process low tSNR data in the same way\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OUTPUT_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "# Fetch data\n",
    "high_tsnr_data, high_tsnr_affine = fetch.tsnr_high_philips()\n",
    "# Calculate tSNR map\n",
    "high_tsnr_obj = snr.Tsnr(high_tsnr_data, high_tsnr_affine)\n",
    "# Save as nifti\n",
    "high_tsnr_obj.to_nifti(OUTPUT_DIR, 'high_quality_data')\n",
    "\n",
    "# Process low tSNR data in the same way\n",
    "low_tsnr_data, low_tsnr_affine = fetch.tsnr_low_philips()\n",
    "low_tsnr_obj = snr.Tsnr(low_tsnr_data, low_tsnr_affine)\n",
    "low_tsnr_obj.to_nifti(OUTPUT_DIR, 'low_quality_data')\n",
    "\n",
    "# Display both tSNR maps in the same figure with the same colour scale\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "im = ax1.imshow(np.rot90(high_tsnr_obj.tsnr_map[:, :, 2]), cmap='inferno', clim=(0, 40))\n",
    "cb = fig.colorbar(im, ax=ax1)\n",
    "cb.set_label('tSNR')\n",
    "ax1.set_title('High tSNR Data')\n",
    "ax1.axis('off')\n",
    "\n",
    "im = ax2.imshow(np.rot90(low_tsnr_obj.tsnr_map[:, :, 2], -1), cmap='inferno', clim=(0, 40))\n",
    "cb = fig.colorbar(im, ax=ax2)\n",
    "cb.set_label('tSNR')\n",
    "ax2.set_title('Low tSNR Data')\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
